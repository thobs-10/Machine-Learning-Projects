{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we'll deploy the ride duration model in batch mode. Like in homework 1 and 3, we'll use the FHV data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the version of scikit-learn used\n",
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be kept for ease of changes\n",
    "year = 2021 # we only interested in 2021 data\n",
    "month = 2 # for feb\n",
    "\n",
    "# the files to be inputed for the moddel to use and outputed version of the file\n",
    "input_file = f'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "output_file = f'output/fhv_tripdata_{year:04d}-{month:02d}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bin file that has both the model and the dict vectorizer using pickle\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data and keep only features that are of interest to us\n",
    "# keep the drop off location ID and the pick up location ID\n",
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "# define a function to read the data, prepare in and output the correct dataframe that\n",
    "# will be used for prediction\n",
    "def read_data(filename):\n",
    "    # read the filename that contains the parquet file\n",
    "    df = pd.read_parquet(filename)\n",
    "    # for duration we whave to subtract the pickup time from the drop off time to get the full\n",
    "    # duration of the ride\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    # for duration, we convert the rides into minutes not hour\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    # now we want to have durations that are less than 60 minutes and greater than 1 mminute\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "    # create a categorical feature columns for drop off ID and pick up ID\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to the input file\n",
    "df = read_data(input_file)\n",
    "# format the new column ride_id to have year and date \n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the categorical features into dictionaries of vectors\n",
    "dicts = df[categorical].to_dict(orient='records')\n",
    "# transfrom the dictionaries to vectors\n",
    "X_val = dv.transform(dicts)\n",
    "# predict using the model loaded from the pickle above\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean value for the y_predictions\n",
    "y_pred.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for repdicted results\n",
    "df_result = pd.DataFrame()\n",
    "# use the ride_id as the distinct identifier for each ride\n",
    "df_result['ride_id'] = df['ride_id']\n",
    "# create a predicted duration column for y predictions\n",
    "df_result['predicted_duration'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe of results as a parquet file\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('machine-learning-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74b13156ee32336a91ae017c98b438a6fd9992b5a099c169a831fe64b85fc3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
